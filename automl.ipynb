{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.automl\n",
        "from azureml.core import Workspace, Experiment, Model\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.train.automl.utilities import get_primary_metrics\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import Model\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.automl.core.shared import constants\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1648399014194
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing a Workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "quick-starts-ws-190098\naml-quickstarts-190098\nsouthcentralus\n1b944a9b-fdae-4f97-aeb1-b7eea0beac53\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1648399015230
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an AML Experiment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a name for experiment\n",
        "experiment_name = 'automl-heart-failure'\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "run = experiment.start_logging()\n",
        "\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "Experiment(Name: automl-heart-failure,\nWorkspace: quick-starts-ws-190098)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automl-heart-failure</td><td>quick-starts-ws-190098</td><td><a href=\"https://ml.azure.com/experiments/id/bf250683-e5c0-4e02-abb2-0be596699b18?wsid=/subscriptions/1b944a9b-fdae-4f97-aeb1-b7eea0beac53/resourcegroups/aml-quickstarts-190098/workspaces/quick-starts-ws-190098&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1648399018341
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Compute Cluster"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amlcompute_cluster_name = \"hf-compute\"\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace = ws, name = amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size = 'STANDARD_DS3_V2', max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\nSucceeded................................................................................................................"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     compute_config \u001b[38;5;241m=\u001b[39m AmlCompute\u001b[38;5;241m.\u001b[39mprovisioning_configuration(vm_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTANDARD_DS3_V2\u001b[39m\u001b[38;5;124m'\u001b[39m, max_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      8\u001b[0m     compute_target \u001b[38;5;241m=\u001b[39m ComputeTarget\u001b[38;5;241m.\u001b[39mcreate(ws, amlcompute_cluster_name, compute_config)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mcompute_target\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_node_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_in_minutes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/compute/amlcompute.py:387\u001b[0m, in \u001b[0;36mAmlCompute.wait_for_completion\u001b[0;34m(self, show_output, min_node_count, timeout_in_minutes, is_delete_operation)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28msuper\u001b[39m(AmlCompute, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mwait_for_completion(show_output\u001b[38;5;241m=\u001b[39mshow_output,\n\u001b[1;32m    384\u001b[0m                                                 is_delete_operation\u001b[38;5;241m=\u001b[39mis_delete_operation)\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_delete_operation:\n\u001b[1;32m    386\u001b[0m     min_nodes_reached, timeout_reached, terminal_state_reached, status_errors_present \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 387\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_node_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_in_minutes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmlCompute wait for completion finished\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/compute/amlcompute.py:455\u001b[0m, in \u001b[0;36mAmlCompute._wait_for_nodes\u001b[0;34m(self, min_node_count, timeout_in_minutes, show_output)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mcurrent_node_count:\n\u001b[1;32m    452\u001b[0m         sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting for cluster to scale. \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m nodes ready.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m                          \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mcurrent_node_count, min_node_count))\n\u001b[0;32m--> 455\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefresh_state()\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1648394771536
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Wrangling"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Gathering\n",
        "\n",
        "### Overview\n",
        "In this project, the Heart Failure Prediction dataset from Kaggle is used. The description of the dataset is provided below.\n",
        "\n",
        "**The dataset has the following features:**  \n",
        "* age: Age (numeric)\n",
        "* anaemia: Decrease of red blood cells or hemoglobin (boolean)\n",
        "* creatinine_phosphokinase: Level of the CPK enzyme in the blood (mcg/L)\n",
        "* diabetes: If the patient has diabetes (boolean)\n",
        "* ejection_fraction: Percentage of blood leaving the heart at each contraction (percentage)\n",
        "* high_blood_pressure: If the patient has hypertension (boolean)\n",
        "* platelets: Platelets in the blood (kiloplatelets/mL)\n",
        "* serum_creatinine: Level of serum creatinine in the blood (mg/dL)\n",
        "* serum_sodium: Level of serum sodium in the blood (mEq/L)\n",
        "* sex: Woman or man (binary)\n",
        "\n",
        "**The task:**  \n",
        "Developing a ML model to predict death events using 12 clinical features."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "### Gathering the Dataset\n",
        "data_path = \"https://raw.githubusercontent.com/ugururesin/Azure-ML-Capstone-Project/main/dataset/heart_failure_clinical_records_dataset.csv\"\n",
        "\n",
        "\n",
        "exist = False\n",
        "key = \"heart-failure\"\n",
        "description_text = \"heart failure dataset for binary classification\"\n",
        "\n",
        "if key in ws.datasets.keys(): \n",
        "        exist = True\n",
        "        dataset = ws.datasets[key] \n",
        "        \n",
        "\n",
        "if not exist:\n",
        "        #Creating automl dataset and registering it into the workspace\n",
        "        dataset = Dataset.Tabular.from_delimited_files(data_path)        \n",
        "        \n",
        "        #Register Dataset in Workspace\n",
        "        dataset = dataset.register(workspace=ws,\n",
        "                                   name=key,\n",
        "                                   description=description_text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648394771835
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Assesing"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset.to_pandas_dataframe()\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648394775059
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating training and testing datasets\n",
        "x = df.drop('DEATH_EVENT', axis=1)\n",
        "y = df['DEATH_EVENT']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
        "\n",
        "train_df = pd.concat([x_train, y_train], axis=1)\n",
        "test_df = pd.concat([x_test, y_test], axis=1)\n",
        "\n",
        "train_df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648394775360
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Since pandas dataframe is not supported, the dataset needs to be converted to tabular dataset\n",
        "if not os.path.isdir('dataset'):\n",
        "    os.mkdir('dataset')\n",
        "\n",
        "pd.DataFrame(train_df).to_csv(\"dataset/train_data.csv\", index=False)\n",
        "pd.DataFrame(test_df).to_csv(\"dataset/test_data.csv\", index=False)\n",
        "\n",
        "ds = ws.get_default_datastore()\n",
        "ds.upload(src_dir = './dataset', target_path = 'heart-failure-dataset/train_data.csv')\n",
        "\n",
        "train_data = Dataset.Tabular.from_delimited_files(path = ds.path('heart-failure-dataset/train_data.csv'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648394777667
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648394777966
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the target feature"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['DEATH_EVENT'].value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648394778216
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_primary_metrics(\"classification\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648394778459
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
        "\n",
        "* **experiment_timeout_minutes**: 15 minutes is set since the dataset is small.\n",
        "\n",
        "* **iterations**: 50 is set since the dataset is small.  \n",
        "\n",
        "* **max_concurrent_iterations**: Represents the maximum number of iterations that would be executed in parallel.\n",
        "\n",
        "* **n_cross_validations**: To avoid overfitting and ensure randomness.\n",
        "\n",
        "* **primary_metric**: Accuracy is selected to be able to compare with HyperDrive's results.\n",
        "\n",
        "* **task**: Classification is selected since the response variable is binary (0 or 1).  \n",
        "\n",
        "* **enable_early_stopping**: Activated to avoid overfitting."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 15,\n",
        "    \"iterations\": 50,\n",
        "    \"max_concurrent_iterations\": 3,\n",
        "    \"n_cross_validations\": 3,\n",
        "    \"primary_metric\" : 'accuracy',\n",
        "    \"featurization\" : 'auto',\n",
        "    \"verbosity\": logging.INFO\n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "    task = \"classification\", \n",
        "    training_data = train_data,\n",
        "    label_column_name=\"DEATH_EVENT\",\n",
        "    enable_early_stopping= True,\n",
        "    debug_log = \"automl_errors.log\",\n",
        "    compute_target = compute_target,\n",
        "    **automl_settings\n",
        ")\n",
        "                             "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648398977349
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config, show_output=True)\n",
        "remote_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648398853232
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(remote_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648383260262
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run, fitted_model = remote_run.get_output()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648383267715
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_metrics = best_run.get_metrics()\n",
        "\n",
        "print(\"Best run id : {}\".format(best_run.id), \n",
        "      \"AUC : {}\".format(best_metrics['accuracy']), \n",
        "      \"Best metrics : {}\".format(best_metrics), \n",
        "      \"Best model : {}\".format(fitted_model), sep = '\\n\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648388108381
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the fitted model\n",
        "_, fitted_model = remote_run.get_output()\n",
        "print(fitted_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648383273713
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\r\n",
        "model = best_run.register_model(model_name = \"heart-failure-best-model-automl\", model_path = './outputs/model.pkl')\r\n",
        "print(model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648392135045
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading score.py and env file\n",
        "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648383275792
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# registering the model\n",
        "model_name = best_run.properties['model_name']\n",
        "description = 'AutoML model trained on heart failure data so as to predict whether death event occurs based on the clinical values'\n",
        "tags = None\n",
        "model = remote_run.register_model(model_name = model_name, description = description, tags = tags)\n",
        "\n",
        "print(remote_run.model_id) # This will be written to the script file later in the notebook."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1648383277357
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'best_run_automl.pkl'\r\n",
        "model = remote_run.register_model(model_name = model_name)\r\n",
        "environment = best_run.get_environment()\r\n",
        "\r\n",
        "entry_script='inference/scoring.py'\r\n",
        "best_run.download_file('outputs/scoring_file_v_1_0_0.py', entry_script)\r\n",
        "\r\n",
        "#configuration for inference\r\n",
        "inference_config = InferenceConfig(entry_script = entry_script, environment = environment)\r\n",
        "\r\n",
        "#configuration for deployment and enabling the application insights\r\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \r\n",
        "                                                    memory_gb = 1, \r\n",
        "                                                    auth_enabled= True, \r\n",
        "                                                    enable_app_insights= True)\r\n",
        "\r\n",
        "#deploying the model using azure container instance\r\n",
        "service = Model.deploy(ws, \"aciservice\", [model], inference_config, deployment_config)\r\n",
        "service.wait_for_deployment(show_output = True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1648388739602
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Consume the Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run endpoint.py"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "webservice.get_logs()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#webservice.delete()\n",
        "#compute_target.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}