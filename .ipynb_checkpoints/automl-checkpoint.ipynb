{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1648320842419
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Model\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.train.automl.utilities import get_primary_metrics\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.automl.core.shared import constants\n",
    "\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing a Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1648320843756
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Creating an AML Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1648320852560
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# choose a name for experiment\n",
    "experiment_name = 'automl-heart-failure'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "run = experiment.start_logging()\n",
    "\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Creating a Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1648321457604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded.....................................................................................................................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Wait timeout has been reached\n",
      "Current provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
     ]
    }
   ],
   "source": [
    "amlcompute_cluster_name = \"hf-compute\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace = ws, name = amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = 'STANDARD_DS3_V2', max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "\n",
    "### Overview\n",
    "In this project, the Heart Failure Prediction dataset from Kaggle is used. The description of the dataset is provided below.\n",
    "\n",
    "**The dataset has the following features:**  \n",
    "* age: Age (numeric)\n",
    "* anaemia: Decrease of red blood cells or hemoglobin (boolean)\n",
    "* creatinine_phosphokinase: Level of the CPK enzyme in the blood (mcg/L)\n",
    "* diabetes: If the patient has diabetes (boolean)\n",
    "* ejection_fraction: Percentage of blood leaving the heart at each contraction (percentage)\n",
    "* high_blood_pressure: If the patient has hypertension (boolean)\n",
    "* platelets: Platelets in the blood (kiloplatelets/mL)\n",
    "* serum_creatinine: Level of serum creatinine in the blood (mg/dL)\n",
    "* serum_sodium: Level of serum sodium in the blood (mEq/L)\n",
    "* sex: Woman or man (binary)\n",
    "\n",
    "**The task:**  \n",
    "Developing a ML model to predict death events using 12 clinical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1648321467202
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9e837e9b0ae3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdescription_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"heart failure dataset for binary classification\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mexist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ws' is not defined"
     ]
    }
   ],
   "source": [
    "### Gathering the Dataset\n",
    "data_path = \"https://raw.githubusercontent.com/ugururesin/Azure-ML-Capstone-Project/main/dataset/heart_failure_clinical_records_dataset.csv\"\n",
    "\n",
    "\n",
    "exist = False\n",
    "key = \"heart-failure\"\n",
    "description_text = \"heart failure dataset for binary classification\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        exist = True\n",
    "        dataset = ws.datasets[key] \n",
    "        \n",
    "\n",
    "if not found:\n",
    "        #Creating automl dataset and registering it into the workspace\n",
    "        dataset = Dataset.Tabular.from_delimited_files(data_path)        \n",
    "        \n",
    "        #Register Dataset in Workspace\n",
    "        dataset = dataset.register(workspace=ws,\n",
    "                                   name=key,\n",
    "                                   description=description_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1648321509959
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.to_pandas_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1648323973764
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.18</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>242000.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>267000.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1419</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>105000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>382000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "64   45.0        0                       582         0                 80   \n",
       "160  66.0        1                        72         0                 40   \n",
       "178  63.0        1                       122         1                 60   \n",
       "176  69.0        0                      1419         0                 40   \n",
       "292  52.0        0                       190         1                 38   \n",
       "\n",
       "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "64                     0  263358.03              1.18           137    0   \n",
       "160                    1  242000.00              1.20           134    1   \n",
       "178                    0  267000.00              1.20           145    1   \n",
       "176                    0  105000.00              1.00           135    1   \n",
       "292                    0  382000.00              1.00           140    1   \n",
       "\n",
       "     smoking  time  DEATH_EVENT  \n",
       "64         0    63            0  \n",
       "160        0   121            0  \n",
       "178        0   147            0  \n",
       "176        1   147            0  \n",
       "292        1   258            0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating training and testing datasets\n",
    "x = df.drop('DEATH_EVENT', axis=1)\n",
    "y = df['DEATH_EVENT']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "train_df = pd.concat([x_train, y_train], axis=1)\n",
    "test_df = pd.concat([x_test, y_test], axis=1)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1648323334851
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    }
   ],
   "source": [
    "#Since pandas dataframe is not supported, the dataset needs to be converted to tabular dataset\n",
    "if not os.path.isdir('dataset'):\n",
    "    os.mkdir('dataset')\n",
    "\n",
    "pd.DataFrame(train_df).to_csv(\"dataset/train_data.csv\", index=False)\n",
    "pd.DataFrame(test_df).to_csv(\"dataset/test_data.csv\", index=False)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir = './dataset', target_path = 'heart-failure-dataset/train_data.csv')\n",
    "\n",
    "train_data = Dataset.Tabular.from_delimited_files(path = ds.path('heart-failure-dataset/train_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1648323489015
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'heart-failure-dataset/train_data.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"ee9ef731-d878-408d-b64e-a29485319efc\",\n",
       "    \"name\": null,\n",
       "    \"version\": null,\n",
       "    \"workspace\": \"Workspace.create(name='quick-starts-ws-190058', subscription_id='3d1a56d2-7c81-4118-9790-f85d1acf0c77', resource_group='aml-quickstarts-190058')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Checking the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1648321521090
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    203\n",
       "1     96\n",
       "Name: DEATH_EVENT, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DEATH_EVENT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1648321523918
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['precision_score_weighted',\n",
       " 'norm_macro_recall',\n",
       " 'average_precision_score_weighted',\n",
       " 'accuracy',\n",
       " 'AUC_weighted']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_primary_metrics(\"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below.\n",
    "\n",
    "* **experiment_timeout_minutes**: 15 minutes is set since the dataset is small.\n",
    "\n",
    "* **iterations**: 50 is set since the dataset is small.  \n",
    "\n",
    "* **max_concurrent_iterations**: Represents the maximum number of iterations that would be executed in parallel.\n",
    "\n",
    "* **n_cross_validations**: To avoid overfitting and ensure randomness.\n",
    "\n",
    "* **primary_metric**: Since the target response is imbalanced, accuracy is not a good evaluation metric. So, auc is selected.  \n",
    "\n",
    "* **task**: Classification is selected since the response variable is binary (0 or 1).  \n",
    "\n",
    "* **enable_early_stopping**: Activated to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1648323557879
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Put your automl settings here\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 15,\n",
    "    \"iterations\": 50,\n",
    "    \"max_concurrent_iterations\": 3,\n",
    "    \"n_cross_validations\": 3,\n",
    "    \"primary_metric\" : 'AUC_weighted',\n",
    "    \"featurization\" : 'auto',\n",
    "    \"verbosity\": logging.INFO\n",
    "}\n",
    "\n",
    "# TODO: Put your automl config here\n",
    "automl_config = AutoMLConfig(\n",
    "    task = \"classification\", \n",
    "    training_data = train_data,\n",
    "    label_column_name=\"DEATH_EVENT\",\n",
    "    enable_early_stopping= True,\n",
    "    debug_log = \"automl_errors.log\",\n",
    "    compute_target = compute_target,\n",
    "    **automl_settings\n",
    ")\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting remote run.\n",
      "No run_configuration provided, running on hf-compute with default configuration\n",
      "Running on remote compute: hf-compute\n",
      "The validation results are as follows:\n",
      "Y is empty\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "ValidationException:\n\tMessage: Failed to execute the requested operation: data/settings validation. Error details: Validation error(s): [{\n    \"additional_properties\": {\n        \"debugInfo\": null\n    },\n    \"code\": \"UserError\",\n    \"severity\": 2,\n    \"message\": \"Y is empty\",\n    \"message_format\": \"{dataName} is empty\",\n    \"message_parameters\": {\n        \"dataName\": \"Y\"\n    },\n    \"reference_code\": null,\n    \"details_uri\": null,\n    \"target\": \"training_data\",\n    \"details\": [\n        {\n            \"additional_properties\": {\n                \"debugInfo\": null\n            },\n            \"code\": null,\n            \"severity\": null,\n            \"message\": \"null\",\n            \"message_format\": null,\n            \"message_parameters\": {},\n            \"reference_code\": null,\n            \"details_uri\": null,\n            \"target\": null,\n            \"details\": [],\n            \"inner_error\": null,\n            \"additional_info\": null\n        }\n    ],\n    \"inner_error\": {\n        \"additional_properties\": {},\n        \"code\": \"BadData\",\n        \"inner_error\": {\n            \"additional_properties\": {},\n            \"code\": \"EmptyData\",\n            \"inner_error\": null\n        }\n    },\n    \"additional_info\": null\n}]\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to execute the requested operation: data/settings validation. Error details: Validation error(s): [{\\n    \\\"additional_properties\\\": {\\n        \\\"debugInfo\\\": null\\n    },\\n    \\\"code\\\": \\\"UserError\\\",\\n    \\\"severity\\\": 2,\\n    \\\"message\\\": \\\"Y is empty\\\",\\n    \\\"message_format\\\": \\\"{dataName} is empty\\\",\\n    \\\"message_parameters\\\": {\\n        \\\"dataName\\\": \\\"Y\\\"\\n    },\\n    \\\"reference_code\\\": null,\\n    \\\"details_uri\\\": null,\\n    \\\"target\\\": \\\"training_data\\\",\\n    \\\"details\\\": [\\n        {\\n            \\\"additional_properties\\\": {\\n                \\\"debugInfo\\\": null\\n            },\\n            \\\"code\\\": null,\\n            \\\"severity\\\": null,\\n            \\\"message\\\": \\\"null\\\",\\n            \\\"message_format\\\": null,\\n            \\\"message_parameters\\\": {},\\n            \\\"reference_code\\\": null,\\n            \\\"details_uri\\\": null,\\n            \\\"target\\\": null,\\n            \\\"details\\\": [],\\n            \\\"inner_error\\\": null,\\n            \\\"additional_info\\\": null\\n        }\\n    ],\\n    \\\"inner_error\\\": {\\n        \\\"additional_properties\\\": {},\\n        \\\"code\\\": \\\"BadData\\\",\\n        \\\"inner_error\\\": {\\n            \\\"additional_properties\\\": {},\\n            \\\"code\\\": \\\"EmptyData\\\",\\n            \\\"inner_error\\\": null\\n        }\\n    },\\n    \\\"additional_info\\\": null\\n}]\",\n        \"inner_error\": {\n            \"code\": \"ExecutionFailure\"\n        }\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Submit your experiment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m remote_run \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoml_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/experiment.py:220\u001b[0m, in \u001b[0;36mExperiment.submit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m submit_func \u001b[38;5;241m=\u001b[39m get_experiment_submit(config)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmit config \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)):\n\u001b[0;32m--> 220\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43msubmit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     run\u001b[38;5;241m.\u001b[39mset_tags(tags)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/automlconfig.py:96\u001b[0m, in \u001b[0;36m_automl_static_submit\u001b[0;34m(automl_config_object, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m settings \u001b[38;5;241m=\u001b[39m _azureautomlsettings\u001b[38;5;241m.\u001b[39mAzureAutoMLSettings(experiment\u001b[38;5;241m=\u001b[39mexperiment, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_dict)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_server\u001b[38;5;241m.\u001b[39mnew_log_context(parent_run_id\u001b[38;5;241m=\u001b[39mparent_run_id):\n\u001b[0;32m---> 96\u001b[0m     automl_run \u001b[38;5;241m=\u001b[39m \u001b[43m_start_execution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     automl_run\u001b[38;5;241m.\u001b[39madd_properties(global_tracking_info_registry\u001b[38;5;241m.\u001b[39mgather_all(settings\u001b[38;5;241m.\u001b[39mpath))\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m automl_run\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/automlconfig.py:225\u001b[0m, in \u001b[0;36m_start_execution\u001b[0;34m(experiment, settings_obj, fit_params, run_config, compute_target, parent_run_id, show_output)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m settings_obj\u001b[38;5;241m.\u001b[39mscenario \u001b[38;5;241m==\u001b[39m constants\u001b[38;5;241m.\u001b[39mScenarios\u001b[38;5;241m.\u001b[39m_NON_PROD:\n\u001b[1;32m    224\u001b[0m         validate_non_prod_env_exists(experiment\u001b[38;5;241m.\u001b[39mworkspace)\n\u001b[0;32m--> 225\u001b[0m     automl_run \u001b[38;5;241m=\u001b[39m \u001b[43m_default_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m automl_run\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/automlconfig.py:127\u001b[0m, in \u001b[0;36m_default_execution\u001b[0;34m(experiment, settings_obj, fit_params, legacy_local, show_output, parent_run_id)\u001b[0m\n\u001b[1;32m    125\u001b[0m experiment_state\u001b[38;5;241m.\u001b[39mconsole_writer\u001b[38;5;241m.\u001b[39mshow_output \u001b[38;5;241m=\u001b[39m show_output\n\u001b[1;32m    126\u001b[0m driver \u001b[38;5;241m=\u001b[39m ExperimentDriver(experiment_state)\n\u001b[0;32m--> 127\u001b[0m updated_params \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_parent_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m fit_params\u001b[38;5;241m.\u001b[39mupdate(updated_params)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/_experiment_drivers/experiment_driver.py:205\u001b[0m, in \u001b[0;36mExperimentDriver.create_parent_run\u001b[0;34m(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m X, y, sample_weight, X_valid, y_valid, sample_weight_valid \u001b[38;5;241m=\u001b[39m dataset_utilities\u001b[38;5;241m.\u001b[39mconvert_inputs(\n\u001b[1;32m    186\u001b[0m     X, y, sample_weight, X_valid,\n\u001b[1;32m    187\u001b[0m     y_valid, sample_weight_valid\n\u001b[1;32m    188\u001b[0m )\n\u001b[1;32m    190\u001b[0m updated_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: X,\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs\n\u001b[1;32m    203\u001b[0m }\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_parent_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_splits_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexisting_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_script_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mcurrent_run\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mparent_run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mcurrent_run\u001b[38;5;241m.\u001b[39mid\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/_experiment_drivers/remote_experiment_launcher.py:55\u001b[0m, in \u001b[0;36mRemoteExperimentLauncher.create_parent_run\u001b[0;34m(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     run_configuration\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m compute_target\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mconsole_writer\u001b[38;5;241m.\u001b[39mprintln(\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning on remote compute: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(run_configuration\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 55\u001b[0m \u001b[43mdriver_utilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_remote_parent_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_configuration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_splits_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_splits_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mcurrent_run\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/_experiment_drivers/driver_utilities.py:366\u001b[0m, in \u001b[0;36mcreate_remote_parent_run\u001b[0;34m(experiment_state, run_config, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, training_data, validation_data, test_data)\u001b[0m\n\u001b[1;32m    358\u001b[0m run_config \u001b[38;5;241m=\u001b[39m modify_run_configuration(experiment_state\u001b[38;5;241m.\u001b[39mautoml_settings, run_config, logger)\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Uncomment to fall back to curated envs for changing environment behavior\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# run_config_object = modify_run_configuration_curated(self.automl_settings,\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m#                                                      run_config_object,\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m#                                                      self.experiment.workspace,\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m#                                                      logger)\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m parent_run_dto \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_and_validate_parent_run_dto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_splits_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_splits_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart creating parent run.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/_experiment_drivers/driver_utilities.py:80\u001b[0m, in \u001b[0;36mcreate_and_validate_parent_run_dto\u001b[0;34m(experiment_state, target, training_data, validation_data, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, parent_run_id, test_data)\u001b[0m\n\u001b[1;32m     75\u001b[0m dataprep_json \u001b[38;5;241m=\u001b[39m serialize_datasets_to_json(X, X_valid, y, y_valid, sample_weight, sample_weight_valid,\n\u001b[1;32m     76\u001b[0m                                            training_data, validation_data, test_data, cv_splits_indices)\n\u001b[1;32m     78\u001b[0m parent_run_dto \u001b[38;5;241m=\u001b[39m create_parent_run_dto(experiment_state, target, dataprep_json, parent_run_id)\n\u001b[0;32m---> 80\u001b[0m \u001b[43mvalidate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_run_dto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parent_run_dto\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/_experiment_drivers/driver_utilities.py:156\u001b[0m, in \u001b[0;36mvalidate_input\u001b[0;34m(experiment_state, parent_run_dto)\u001b[0m\n\u001b[1;32m    154\u001b[0m         errors\u001b[38;5;241m.\u001b[39mappend(result\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m    155\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation error(s): \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(validation_results\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mdetails)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ValidationException\u001b[38;5;241m.\u001b[39m_with_error(AzureMLError\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    157\u001b[0m     ExecutionFailure, operation_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/settings validation\u001b[39m\u001b[38;5;124m\"\u001b[39m, error_details\u001b[38;5;241m=\u001b[39mmsg)\n\u001b[1;32m    158\u001b[0m )\n",
      "\u001b[0;31mValidationException\u001b[0m: ValidationException:\n\tMessage: Failed to execute the requested operation: data/settings validation. Error details: Validation error(s): [{\n    \"additional_properties\": {\n        \"debugInfo\": null\n    },\n    \"code\": \"UserError\",\n    \"severity\": 2,\n    \"message\": \"Y is empty\",\n    \"message_format\": \"{dataName} is empty\",\n    \"message_parameters\": {\n        \"dataName\": \"Y\"\n    },\n    \"reference_code\": null,\n    \"details_uri\": null,\n    \"target\": \"training_data\",\n    \"details\": [\n        {\n            \"additional_properties\": {\n                \"debugInfo\": null\n            },\n            \"code\": null,\n            \"severity\": null,\n            \"message\": \"null\",\n            \"message_format\": null,\n            \"message_parameters\": {},\n            \"reference_code\": null,\n            \"details_uri\": null,\n            \"target\": null,\n            \"details\": [],\n            \"inner_error\": null,\n            \"additional_info\": null\n        }\n    ],\n    \"inner_error\": {\n        \"additional_properties\": {},\n        \"code\": \"BadData\",\n        \"inner_error\": {\n            \"additional_properties\": {},\n            \"code\": \"EmptyData\",\n            \"inner_error\": null\n        }\n    },\n    \"additional_info\": null\n}]\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to execute the requested operation: data/settings validation. Error details: Validation error(s): [{\\n    \\\"additional_properties\\\": {\\n        \\\"debugInfo\\\": null\\n    },\\n    \\\"code\\\": \\\"UserError\\\",\\n    \\\"severity\\\": 2,\\n    \\\"message\\\": \\\"Y is empty\\\",\\n    \\\"message_format\\\": \\\"{dataName} is empty\\\",\\n    \\\"message_parameters\\\": {\\n        \\\"dataName\\\": \\\"Y\\\"\\n    },\\n    \\\"reference_code\\\": null,\\n    \\\"details_uri\\\": null,\\n    \\\"target\\\": \\\"training_data\\\",\\n    \\\"details\\\": [\\n        {\\n            \\\"additional_properties\\\": {\\n                \\\"debugInfo\\\": null\\n            },\\n            \\\"code\\\": null,\\n            \\\"severity\\\": null,\\n            \\\"message\\\": \\\"null\\\",\\n            \\\"message_format\\\": null,\\n            \\\"message_parameters\\\": {},\\n            \\\"reference_code\\\": null,\\n            \\\"details_uri\\\": null,\\n            \\\"target\\\": null,\\n            \\\"details\\\": [],\\n            \\\"inner_error\\\": null,\\n            \\\"additional_info\\\": null\\n        }\\n    ],\\n    \\\"inner_error\\\": {\\n        \\\"additional_properties\\\": {},\\n        \\\"code\\\": \\\"BadData\\\",\\n        \\\"inner_error\\\": {\\n            \\\"additional_properties\\\": {},\\n            \\\"code\\\": \\\"EmptyData\\\",\\n            \\\"inner_error\\\": null\\n        }\\n    },\\n    \\\"additional_info\\\": null\\n}]\",\n        \"inner_error\": {\n            \"code\": \"ExecutionFailure\"\n        }\n    }\n}"
     ]
    }
   ],
   "source": [
    "# TODO: Submit your experiment\n",
    "remote_run = experiment.submit(automl_config, show_output=True)\n",
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run, fitted_model = remote_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8236b9a0f71a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#TODO: Save the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m print(\"Best run id : {}\".format(best_run.id), \n\u001b[1;32m      5\u001b[0m       \u001b[0;34m\"AUC : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_run' is not defined"
     ]
    }
   ],
   "source": [
    "best_metrics = best_run.get_metrics()\n",
    "\n",
    "print(\"Best run id : {}\".format(best_run.id), \n",
    "      \"AUC : {}\".format(best_metrics['accuracy']), \n",
    "      \"Best metrics : {}\".format(best_metrics), \n",
    "      \"Best model : {}\".format(fitted_model), sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the fitted model\n",
    "_, fitted_model = remote_run.get_output()\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Save the best model\n",
    "best_run.register_model(model_name = 'automl_best_model.pkl', model_path = './outputs/')\n",
    "joblib.dump(fitted_model, filename= \"outputs/automl_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# downloading score.py and env file\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# registering the model\n",
    "model_name = best_run.properties['model_name']\n",
    "description = 'AutoML model trained on heart failure data so as to predict whether death event occurs based on the clinical values'\n",
    "tags = None\n",
    "model = remote_run.register_model(model_name = model_name, description = description, tags = tags)\n",
    "\n",
    "print(remote_run.model_id) # This will be written to the script file later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script = entry_script, environment = environment)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                                    memory_gb = 1, \n",
    "                                                    auth_enabled= True, \n",
    "                                                    enable_app_insights= True)\n",
    "\n",
    "service = Model.deploy(ws, \"aciservice\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a randomly selected test data\n",
    "test_data = df.sample(10)\n",
    "test_label = test_data.pop('DEATH_EVENT')\n",
    "\n",
    "# converting the records to a json data file\n",
    "data_json = test_data.to_dict(orient='records')\n",
    "data = json.dumps({'data': data_json})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting inference\n",
    "output = webservice.run(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webservice.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#webservice.delete()\n",
    "#compute_target.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission Checklist**\n",
    "- I have registered the model.\n",
    "- I have deployed the model with the best accuracy as a webservice.\n",
    "- I have tested the webservice by sending a request to the model endpoint.\n",
    "- I have deleted the webservice and shutdown all the computes that I have used.\n",
    "- I have taken a screenshot showing the model endpoint as active.\n",
    "- The project includes a file containing the environment details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
